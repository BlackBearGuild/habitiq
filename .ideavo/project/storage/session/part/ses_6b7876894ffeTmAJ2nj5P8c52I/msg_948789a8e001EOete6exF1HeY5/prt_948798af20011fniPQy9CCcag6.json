{
  "id": "prt_948798af20011fniPQy9CCcag6",
  "messageID": "msg_948789a8e001EOete6exF1HeY5",
  "sessionID": "ses_6b7876894ffeTmAJ2nj5P8c52I",
  "type": "tool",
  "tool": "write",
  "callID": "toolu_014ymnVJ5pCF9kQwTYcvz4q2",
  "state": {
    "status": "completed",
    "input": {
      "filePath": "/home/user/project/components/voice-input.tsx",
      "content": "\"use client\";\n\nimport { useState, useRef, useEffect } from 'react';\nimport { Mic, MicOff, Loader2 } from 'lucide-react';\nimport { Button } from '@/components/ui/button';\nimport { useToast } from '@/hooks/use-toast';\n\ninterface VoiceInputProps {\n  onTranscript: (transcript: string) => void;\n}\n\nexport function VoiceInput({ onTranscript }: VoiceInputProps) {\n  const [isRecording, setIsRecording] = useState(false);\n  const [isProcessing, setIsProcessing] = useState(false);\n  const [isSupported, setIsSupported] = useState(false);\n  const mediaRecorderRef = useRef<MediaRecorder | null>(null);\n  const chunksRef = useRef<Blob[]>([]);\n  const { toast } = useToast();\n\n  useEffect(() => {\n    setIsSupported(\n      typeof window !== 'undefined' && \n      'webkitSpeechRecognition' in window || 'SpeechRecognition' in window\n    );\n  }, []);\n\n  const startRecording = async () => {\n    if (!isSupported) {\n      toast({\n        title: \"Not supported\",\n        description: \"Speech recognition is not supported in this browser.\",\n        variant: \"destructive\"\n      });\n      return;\n    }\n\n    try {\n      // Use Web Speech API for real-time transcription\n      const SpeechRecognition = (window as any).webkitSpeechRecognition || (window as any).SpeechRecognition;\n      const recognition = new SpeechRecognition();\n      \n      recognition.continuous = true;\n      recognition.interimResults = true;\n      recognition.lang = 'en-US';\n\n      let finalTranscript = '';\n      \n      recognition.onresult = (event: any) => {\n        let interimTranscript = '';\n        \n        for (let i = event.resultIndex; i < event.results.length; i++) {\n          const transcript = event.results[i][0].transcript;\n          \n          if (event.results[i].isFinal) {\n            finalTranscript += transcript + ' ';\n          } else {\n            interimTranscript += transcript;\n          }\n        }\n      };\n\n      recognition.onstart = () => {\n        setIsRecording(true);\n        toast({\n          title: \"Recording started\",\n          description: \"Speak now, I'm listening...\",\n        });\n      };\n\n      recognition.onend = () => {\n        setIsRecording(false);\n        setIsProcessing(true);\n        \n        if (finalTranscript.trim()) {\n          // Convert to markdown format\n          const markdownTranscript = formatAsMarkdown(finalTranscript.trim());\n          onTranscript(markdownTranscript);\n          \n          toast({\n            title: \"Voice note captured!\",\n            description: \"Your transcript has been saved.\",\n          });\n        }\n        \n        setIsProcessing(false);\n      };\n\n      recognition.onerror = (event: any) => {\n        setIsRecording(false);\n        setIsProcessing(false);\n        toast({\n          title: \"Recording error\",\n          description: `Speech recognition error: ${event.error}`,\n          variant: \"destructive\"\n        });\n      };\n\n      recognition.start();\n    } catch (error) {\n      toast({\n        title: \"Error\",\n        description: \"Failed to start voice recording.\",\n        variant: \"destructive\"\n      });\n    }\n  };\n\n  const stopRecording = () => {\n    // Stop speech recognition\n    if (isRecording) {\n      // The recognition will be stopped by calling stop, which triggers onend\n      try {\n        const SpeechRecognition = (window as any).webkitSpeechRecognition || (window as any).SpeechRecognition;\n        // We need to track the recognition instance to stop it\n        // For now, we'll use a timeout approach\n        setIsRecording(false);\n      } catch (error) {\n        console.error('Error stopping recording:', error);\n      }\n    }\n  };\n\n  const formatAsMarkdown = (transcript: string): string => {\n    const timestamp = new Date().toLocaleString();\n    \n    // Basic markdown formatting\n    let formatted = `## Voice Note - ${timestamp}\\n\\n`;\n    \n    // Split into sentences and format\n    const sentences = transcript.split(/[.!?]+/).filter(s => s.trim());\n    \n    if (sentences.length > 1) {\n      formatted += sentences.map(sentence => `- ${sentence.trim()}`).join('\\n');\n    } else {\n      formatted += transcript;\n    }\n    \n    // Add common habit-related formatting\n    formatted = formatted\n      .replace(/\\b(todo|to do|task)\\b/gi, '**$1**')\n      .replace(/\\b(tomorrow|today|remind me)\\b/gi, '***$1***')\n      .replace(/\\b(exercise|workout|gym|run|walk)\\b/gi, '*$1*')\n      .replace(/\\b(water|drink|hydrate)\\b/gi, '*$1*');\n    \n    return formatted;\n  };\n\n  if (!isSupported) {\n    return null;\n  }\n\n  return (\n    <div className=\"flex items-center gap-2\">\n      <Button\n        variant={isRecording ? \"destructive\" : \"outline\"}\n        size=\"sm\"\n        onClick={isRecording ? stopRecording : startRecording}\n        disabled={isProcessing}\n        className={isRecording ? \"animate-pulse\" : \"\"}\n      >\n        {isProcessing ? (\n          <Loader2 className=\"w-4 h-4 animate-spin\" />\n        ) : isRecording ? (\n          <MicOff className=\"w-4 h-4\" />\n        ) : (\n          <Mic className=\"w-4 h-4\" />\n        )}\n        {isProcessing ? 'Processing...' : isRecording ? 'Stop' : 'Voice Note'}\n      </Button>\n      \n      {isRecording && (\n        <div className=\"flex items-center gap-1 text-sm text-red-600 animate-pulse\">\n          <div className=\"w-2 h-2 bg-red-500 rounded-full\"></div>\n          Recording...\n        </div>\n      )}\n    </div>\n  );\n}"
    },
    "output": "",
    "metadata": {
      "diagnostics": {},
      "filepath": "/home/user/project/components/voice-input.tsx",
      "exists": false
    },
    "title": "components/voice-input.tsx",
    "time": {
      "start": 1757857568839,
      "end": 1757857568849
    }
  }
}